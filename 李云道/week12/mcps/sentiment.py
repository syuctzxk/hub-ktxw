import os
from typing import Annotated
from fastmcp import FastMCP
from openai import AsyncOpenAI
import asyncio
import json
from enum import Enum

# åˆå§‹åŒ–FastMCP
mcp = FastMCP(
    name="Sentiment-MCP-Server",
    instructions="æƒ…æ„Ÿåˆ†ææœåŠ¡ï¼Œæä¾›æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»å’Œæƒ…æ„Ÿå¼ºåº¦åˆ†æåŠŸèƒ½ã€‚",
)

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY", "your-api-key-here"),
    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
)


class SentimentLabel(str, Enum):
    """æƒ…æ„Ÿåˆ†ç±»æ ‡ç­¾"""
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    MIXED = "mixed"


class SentimentIntensity(str, Enum):
    """æƒ…æ„Ÿå¼ºåº¦"""
    WEAK = "weak"
    MODERATE = "moderate"
    STRONG = "strong"
    VERY_STRONG = "very_strong"


@mcp.tool
async def sentiment_classification(
        text: Annotated[str, "éœ€è¦åˆ†ææƒ…æ„Ÿçš„æ–‡æœ¬"],
        detailed: Annotated[bool, "æ˜¯å¦è¿”å›è¯¦ç»†åˆ†æ", True] = True
) -> str:
    """å¯¹æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»"""

    # æ„å»ºæç¤ºè¯
    prompt = f"""
è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼š
"{text}"

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›JSONç»“æœï¼š
{{
    "sentiment": "positive|negative|neutral|mixed",
    "confidence": 0.0-1.0,
    "intensity": "weak|moderate|strong|very_strong",
    "explanation": "ç®€è¦è§£é‡Šåˆ†æç»“æœ"
}}

{"å¦‚æœdetailedä¸ºtrueï¼Œè¿˜éœ€è¦åˆ†æå…³é”®æƒ…æ„Ÿè¯å’Œæ•´ä½“æƒ…æ„Ÿå€¾å‘" if detailed else ""}
"""

    try:
        # è°ƒç”¨OpenAI API
        response = await client.chat.completions.create(
            model="qwen-max",  # å¯ä»¥æ ¹æ®éœ€è¦æ”¹ä¸ºgpt-4
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶ã€‚è¯·å‡†ç¡®åˆ†ææ–‡æœ¬æƒ…æ„Ÿå¹¶è¿”å›è§„èŒƒçš„JSONæ ¼å¼ç»“æœã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # ä½æ¸©åº¦ä¿è¯ç»“æœä¸€è‡´æ€§
            response_format={"type": "json_object"}
        )

        # è§£æå“åº”
        result = response.choices[0].message.content
        sentiment_data = json.loads(result)

        # æ„å»ºè¿”å›ç»“æœ
        if detailed:
            return f"""
æƒ…æ„Ÿåˆ†æç»“æœï¼š
- æƒ…æ„Ÿåˆ†ç±»: {sentiment_data.get('sentiment', 'unknown')}
- ç½®ä¿¡åº¦: {sentiment_data.get('confidence', 0) * 100:.1f}%
- æƒ…æ„Ÿå¼ºåº¦: {sentiment_data.get('intensity', 'unknown')}
- åˆ†æè¯´æ˜: {sentiment_data.get('explanation', 'æ— ')}
"""
        else:
            return f"æƒ…æ„Ÿåˆ†ç±»: {sentiment_data.get('sentiment', 'unknown')} (ç½®ä¿¡åº¦: {sentiment_data.get('confidence', 0) * 100:.1f}%)"

    except Exception as e:
        return f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}"


@mcp.tool
async def sentiment_comparison(
        text1: Annotated[str, "ç¬¬ä¸€æ®µæ–‡æœ¬"],
        text2: Annotated[str, "ç¬¬äºŒæ®µæ–‡æœ¬"]
) -> str:
    """æ¯”è¾ƒä¸¤æ®µæ–‡æœ¬çš„æƒ…æ„Ÿå·®å¼‚"""

    prompt = f"""
è¯·æ¯”è¾ƒä»¥ä¸‹ä¸¤æ®µæ–‡æœ¬çš„æƒ…æ„Ÿå·®å¼‚ï¼š

æ–‡æœ¬1: "{text1}"

æ–‡æœ¬2: "{text2}"

è¯·è¿”å›JSONæ ¼å¼çš„æ¯”è¾ƒç»“æœï¼š
{{
    "text1_sentiment": "positive|negative|neutral|mixed",
    "text2_sentiment": "positive|negative|neutral|mixed", 
    "sentiment_difference": "similar|slightly_different|very_different|opposite",
    "comparison_analysis": "è¯¦ç»†æ¯”è¾ƒåˆ†æ",
    "overall_tendency": "å“ªæ®µæ–‡æœ¬æ›´ç§¯æ/æ¶ˆæ"
}}
"""

    try:
        response = await client.chat.completions.create(
            model="qwen-max",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶ï¼Œæ“…é•¿æ¯”è¾ƒä¸åŒæ–‡æœ¬çš„æƒ…æ„Ÿå·®å¼‚ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )

        result = response.choices[0].message.content
        comparison_data = json.loads(result)

        return f"""
æƒ…æ„Ÿæ¯”è¾ƒç»“æœï¼š
ğŸ“Š æ–‡æœ¬1æƒ…æ„Ÿ: {comparison_data.get('text1_sentiment', 'unknown')}
ğŸ“Š æ–‡æœ¬2æƒ…æ„Ÿ: {comparison_data.get('text2_sentiment', 'unknown')}
ğŸ” æƒ…æ„Ÿå·®å¼‚: {comparison_data.get('sentiment_difference', 'unknown')}
ğŸ“ˆ æ€»ä½“å€¾å‘: {comparison_data.get('overall_tendency', 'æœªçŸ¥')}

è¯¦ç»†åˆ†æ:
{comparison_data.get('comparison_analysis', 'æ— ')}
"""
    except Exception as e:
        return f"æƒ…æ„Ÿæ¯”è¾ƒå¤±è´¥: {str(e)}"



@mcp.tool
async def emotional_trend_analysis(
        texts: Annotated[list, "æŒ‰æ—¶é—´é¡ºåºçš„æ–‡æœ¬åˆ—è¡¨"],
        timeframe: Annotated[str, "æ—¶é—´èŒƒå›´æè¿°", "è¿‘æœŸ"] = "è¿‘æœŸ"
) -> str:
    """åˆ†ææƒ…æ„Ÿè¶‹åŠ¿å˜åŒ–"""

    if len(texts) < 2:
        return "é”™è¯¯ï¼šè‡³å°‘éœ€è¦2æ®µæ–‡æœ¬æ¥åˆ†æè¶‹åŠ¿"

    prompt = f"""
è¯·åˆ†æä»¥ä¸‹{len(texts)}æ®µæ–‡æœ¬çš„æƒ…æ„Ÿè¶‹åŠ¿å˜åŒ–ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰ï¼š

{chr(10).join([f'æ—¶é—´æ®µ {i + 1}: "{text}"' for i, text in enumerate(texts)])}

è¯·åˆ†ææƒ…æ„Ÿè¶‹åŠ¿å˜åŒ–å¹¶è¿”å›JSONç»“æœï¼š
{{
    "trend_analysis": "æƒ…æ„Ÿå˜åŒ–è¶‹åŠ¿æè¿°",
    "key_turning_points": ["å…³é”®è½¬æŠ˜ç‚¹æè¿°"],
    "overall_trend": "improving|deteriorating|stable|fluctuating",
    "recommendations": ["åŸºäºæƒ…æ„Ÿè¶‹åŠ¿çš„å»ºè®®"]
}}
"""

    try:
        response = await client.chat.completions.create(
            model="qwen-max",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†ææƒ…æ„Ÿè¶‹åŠ¿å˜åŒ–ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )

        result = response.choices[0].message.content
        trend_data = json.loads(result)

        return f"""
ğŸ“ˆ {timeframe}æƒ…æ„Ÿè¶‹åŠ¿åˆ†æï¼š

è¶‹åŠ¿åˆ†æ: {trend_data.get('trend_analysis', 'æ— ')}
æ€»ä½“è¶‹åŠ¿: {trend_data.get('overall_trend', 'æœªçŸ¥')}

ğŸ” å…³é”®è½¬æŠ˜ç‚¹:
{chr(10).join(['â€¢ ' + point for point in trend_data.get('key_turning_points', [])]) or 'æ— '}

ğŸ’¡ å»ºè®®:
{chr(10).join(['â€¢ ' + rec for rec in trend_data.get('recommendations', [])]) or 'æ— '}
"""
    except Exception as e:
        return f"æƒ…æ„Ÿè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}"


# è¿è¡ŒæœåŠ¡å™¨
if __name__ == "__main__":
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv("OPENAI_API_KEY"):
        print("è­¦å‘Š: æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤å¯†é’¥")

    # å¯åŠ¨MCPæœåŠ¡å™¨
    print("å¯åŠ¨æƒ…æ„Ÿåˆ†æMCPæœåŠ¡å™¨...")
    print("æœåŠ¡ç«¯ç‚¹: http://localhost:8903/sse")

    mcp.run(transport="sse", port=8903)