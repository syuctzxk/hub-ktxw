## 思路一

### 流程

1. 知识库准备：PDF解析为MD，合并为Excel文件，每一页PDF转成的MD文本和合并后的完整文本作为知识库
2. 将用户输入的问题用**Qwen3-Embedding-0.6B**模型转为向量
3. 计算问题与知识库中的内容的余弦相似度，检索top8相关语料
4. 构造提示词
5. 调用云端***Qwen3-235B-A22B-Thinking-2507***大模型选择公式，并自主计算结果
6. 保存大模型的原始回答，并将思考过程、公式选择、计算步骤和最终结果写入jsonl
7. 用正则方法匹配answer字段，无匹配则默认为10，将问题和答案保存至csv

#### 效果

- 检索精度适中，采用了通用的embedding模型
- 计算精度极低，因为是大模型直接内部计算

#### 优缺点

- 优点：直接调用云端模型，不需要本地部署，全程自动化实现
- 缺点：计算精度极低，会消耗大量token

## 思路二

### 流程

1. 知识库准备：即match.csv，第一列为问题，第二列为对应文本，全为人工匹配
2. 构造提示词
3. 遍历所有问题和对应文本，调用本地的**Qwen2.5-7B**模型，理解问题并提取公式的参数，然后直接自主计算结果
4. 将大模型的输出结果直接保存到content_list2.csv中

#### 效果

- 检索精度非常高，因为是人工匹配，无误差或误差极低
- 计算精度适中，还是由大模型直接内部计算

#### 优缺点

- 优点：模型本地部署不依赖网络、人工匹配精度高
- 缺点：需要巨大人工成本，计算精度低

## 思路三

### 流程

1. 知识库准备：ZIP包解析PDF / MD，然后合并形成知识库

2. 将用户输入的问题用**中文句向量**模型转为向量

3. 构造提示词

4. 计算问题与知识库中的内容的余弦相似度，检索top3相关文档

5. 通过Ollama调用**Qwen3:8B**模型，选择最相关的文档，分析问题意图并结构化输出

   问题意图归为三类：

   - `numerical_calculation`：数值计算

     1. 大模型提取公式和参数
     2. sympy精确计算数值结果
     3. 如果失败，则返回0.0

   - `formula-retrieval`：返回核心数学模型

     直接使用大模型进行公示提取

   - `conclusion_derivation`：基于模型进行逻辑的推断

     直接使用大模型进行结论推断

6. 输出结果，将问题、检索文档 ID、大模型原始输出和最终答案保存为jsonl

#### 效果

- 检索精度高，因为采用的是中文句向量，比通用embedding模型更好地理解中文，中文语义空间更加准确
- 计算精度高，采用sympy精确计算，不通过大模型内部计算

#### 优缺点

- 优点：检索精度高，计算精度高，不需要人工参与，流程规范
- 缺点：需要本地部署Ollama和模型
