
##一、知识库构建（准备原始知识）
### 目标：收集并整理需要让大模型参考的“外部知识源”，确保知识的准确性和相关性。
+ 1.1 知识来源
- 文档类型：PDF、Word、TXT、Markdown、网页（HTML）、数据库数据等。
##二、文档预处理（清洗与分割文本）
###目标：将原始文档处理为“小而精”的文本片段（Chunk），避免长文本检索效率低、相关性差的问题。
+ 2.1 文本清洗
- 去除无关内容：格式符号（如  \n 、 \t ）、广告、重复段落、乱码等。
- 统一格式：将PDF/Word的表格、图片说明转为纯文本（可用  pdfplumber  处理PDF）。
+ 2.2 文本分割（Chunking）
- 核心原则：每个Chunk保留完整语义（如一个段落、一个小节），同时控制长度（避免超过大模型上下文或向量化模型的Token限制）。
- 常用工具： LangChain  的  RecursiveCharacterTextSplitter （按标点、换行分割，适合大多数文本）。
##三、文本向量化（将文本转为向量）
###目标：用向量化模型将文本Chunk转换为高维向量（Embedding），向量的距离反映文本语义的相似度。
+ 3.1 选择向量化模型
- 中文场景：BAAI  bge-large-zh-v1.5 （开源、效果好）、智谱AI  glm-embedding  等。
- 英文场景：OpenAI  text-embedding-ada-002 、 all-MiniLM-L6-v2 （轻量开源）等。
##四、向量存储（存入向量数据库）
###目标：将文本Chunk及其向量存入向量数据库，实现高效的相似度检索（支持快速查询与用户问题最相关的Chunk）。
+ 4.1 选择向量数据库
- 本地轻量：Chroma（无需部署，适合测试）、FAISS（Facebook开源，纯Python）。
- 生产环境：Pinecone（云端托管）、Milvus（开源分布式）、Weaviate（支持语义搜索）。
##五、检索相关文档（根据问题找相关知识）
###目标：用户提问时，将问题转为向量，从向量数据库中检索最相关的文本Chunk。
+ 5.1 检索流程
-  将用户问题转为向量。
-  计算问题向量与数据库中所有Chunk向量的相似度（余弦相似度）。
-  返回Top-K个最相似的Chunk（通常K=3-5，避免信息过载）。
##六、大模型生成（结合知识生成回答）
###目标：让大模型参考检索到的Chunk，生成基于知识的准确回答（避免幻觉）。
+ 6.1 选择大模型
- 开源模型：Llama 3、Qwen（通义千问）、Mistral等（需本地部署或用API）。
- 闭源API：GPT-3.5/4、Claude、文心一言等（通过官方API调用）。
+ 6.2 构建Prompt（关键步骤）
- Prompt需明确要求模型“基于检索到的知识回答”
+ 6.3 调用大模型生成回答
##七、优化与迭代（可选但重要）
###实际应用中需不断优化效果，常见方向：
+ Chunk优化：调整  chunk_size  和  chunk_overlap （如长文档用1000Token，短文档用300Token）。
+ 检索增强：
- 混合检索：结合“关键词检索”（如Elasticsearch）和“向量检索”，提高召回率。
- 重排序（Reranking）：用模型（如  bge-reranker-large ）对检索结果二次排序，提升相关性。
- Prompt优化：明确要求模型“引用知识中的具体内容”“分点回答”等。
- 评估效果：通过人工标注或自动指标（如BLEU、ROUGE）评估回答的准确性和相关性。
