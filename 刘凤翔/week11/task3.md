
## ğŸ—ï¸ æ•´ä½“æ•°æ®ç»“æ„è®¾è®¡

### 1. åŸºç¡€å…ƒæ•°æ®å­—æ®µ
```python
# åŸºç¡€å…ƒæ•°æ®å­—æ®µè®¾è®¡
base_schema = {
    "id": "INT64",  # ä¸»é”®
    "data_type": "VARCHAR",  # æ•°æ®ç±»å‹: text/image/table
    "source_id": "VARCHAR",  # åŸå§‹æ•°æ®æºID
    "created_time": "VARCHAR",  # åˆ›å»ºæ—¶é—´
    "updated_time": "VARCHAR",  # æ›´æ–°æ—¶é—´
    "metadata": "JSON",  # æ‰©å±•å…ƒæ•°æ®
}
```

### 2. æ–‡æœ¬æ•°æ®ä¸“ç”¨å­—æ®µ
```python
text_schema = {
    "text_content": "VARCHAR(65535)",  # æ–‡æœ¬å†…å®¹
    "text_length": "INT32",  # æ–‡æœ¬é•¿åº¦
    "language": "VARCHAR",  # è¯­è¨€ç±»å‹
    "category": "VARCHAR",  # æ–‡æœ¬åˆ†ç±»
}
```

### 3. å›¾åƒæ•°æ®ä¸“ç”¨å­—æ®µ
```python
image_schema = {
    "image_path": "VARCHAR",  # å›¾ç‰‡è·¯å¾„/URL
    "image_format": "VARCHAR",  # å›¾ç‰‡æ ¼å¼
    "image_size": "INT64",  # æ–‡ä»¶å¤§å°
    "image_dimensions": "VARCHAR",  # å›¾ç‰‡å°ºå¯¸ "1920x1080"
    "dominant_colors": "JSON",  # ä¸»è‰²è°ƒ
}
```

### 4. è¡¨æ ¼æ•°æ®ä¸“ç”¨å­—æ®µ
```python
table_schema = {
    "table_name": "VARCHAR",  # è¡¨å
    "table_schema": "JSON",  # è¡¨ç»“æ„
    "row_count": "INT32",  # è¡Œæ•°
    "column_count": "INT32",  # åˆ—æ•°
    "table_summary": "VARCHAR",  # è¡¨æ ¼æ‘˜è¦
}
```

## ğŸ”„ å‘é‡å­—æ®µè®¾è®¡ç­–ç•¥

### æ–¹æ¡ˆä¸€ï¼šç»Ÿä¸€å‘é‡å­—æ®µï¼ˆæ¨èï¼‰
```python
# ç»Ÿä¸€çš„å‘é‡å­—æ®µè®¾è®¡
vector_schema = {
    # å¤šæ¨¡æ€ç»Ÿä¸€å‘é‡ (ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹å¦‚CLIPã€BLIPç­‰)
    "multimodal_vector": "FLOAT_VECTOR(512)",
    
    # æ–‡æœ¬ä¸“ç”¨å‘é‡ (ä½¿ç”¨æ–‡æœ¬ä¼˜åŒ–æ¨¡å‹å¦‚BGEã€Sentence-BERT)
    "text_semantic_vector": "FLOAT_VECTOR(768)", 
    
    # å›¾åƒä¸“ç”¨å‘é‡ (ä½¿ç”¨è§†è§‰æ¨¡å‹å¦‚ResNetã€ViT)
    "image_visual_vector": "FLOAT_VECTOR(512)",
    
    # è¡¨æ ¼ç»“æ„åŒ–å‘é‡ (ä½¿ç”¨è¡¨æ ¼ç¼–ç æ¨¡å‹)
    "table_structural_vector": "FLOAT_VECTOR(256)",
}
```

### æ–¹æ¡ˆäºŒï¼šæŒ‰æ¨¡æ€åˆ†é›†åˆï¼ˆå¤§è§„æ¨¡åœºæ™¯ï¼‰
```python
# æ–‡æœ¬ä¸“ç”¨é›†åˆ
text_collection_schema = {
    "text_bge_vector": "FLOAT_VECTOR(768)",
    "text_clip_vector": "FLOAT_VECTOR(512)",
}

# å›¾åƒä¸“ç”¨é›†åˆ  
image_collection_schema = {
    "image_clip_vector": "FLOAT_VECTOR(512)",
    "image_resnet_vector": "FLOAT_VECTOR(2048)",
}

# è¡¨æ ¼ä¸“ç”¨é›†åˆ
table_collection_schema = {
    "table_semantic_vector": "FLOAT_VECTOR(512)",
    "table_schema_vector": "FLOAT_VECTOR(256)",
}
```

## ğŸ“Š å®Œæ•´é›†åˆæ¶æ„

### ä¸»é›†åˆè®¾è®¡ï¼ˆæ¨èç”¨äºä¸­å°è§„æ¨¡ï¼‰
```python
def create_multimodal_collection():
    schema = MilvusClient.create_schema(
        auto_id=True,
        enable_dynamic_field=True
    )
    
    # åŸºç¡€å­—æ®µ
    schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True)
    schema.add_field(field_name="data_type", datatype=DataType.VARCHAR, max_length=50)
    schema.add_field(field_name="source_id", datatype=DataType.VARCHAR, max_length=200)
    schema.add_field(field_name="created_time", datatype=DataType.VARCHAR, max_length=50)
    schema.add_field(field_name="updated_time", datatype=DataType.VARCHAR, max_length=50)
    
    # å†…å®¹å­—æ®µ
    schema.add_field(field_name="content", datatype=DataType.VARCHAR, max_length=65535)
    schema.add_field(field_name="file_path", datatype=DataType.VARCHAR, max_length=500)
    schema.add_field(field_name="file_format", datatype=DataType.VARCHAR, max_length=20)
    
    # å…ƒæ•°æ®å­—æ®µ
    schema.add_field(field_name="metadata", datatype=DataType.JSON)
    
    # å‘é‡å­—æ®µ
    schema.add_field(field_name="multimodal_vector", datatype=DataType.FLOAT_VECTOR, dim=512)
    schema.add_field(field_name="text_semantic_vector", datatype=DataType.FLOAT_VECTOR, dim=768)
    schema.add_field(field_name="image_visual_vector", datatype=DataType.FLOAT_VECTOR, dim=512)
    schema.add_field(field_name="table_structural_vector", datatype=DataType.FLOAT_VECTOR, dim=256)
    
    # ç´¢å¼•é…ç½®
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "COSINE", 
        "params": {"nlist": 1024}
    }
    
    collection = client.create_collection(
        collection_name="multimodal_rag",
        schema=schema,
        index_params=index_params
    )
    
    return collection
```

## ğŸ¯ æ•°æ®æ’å…¥ç¤ºä¾‹

### æ–‡æœ¬æ•°æ®æ’å…¥
```python
def insert_text_data(text_content, metadata=None):
    # æ–‡æœ¬ç‰¹å¾æå–
    text_semantic_vector = get_text_bge_features([text_content])[0]
    multimodal_vector = get_clip_text_features([text_content])[0]
    
    data = {
        "data_type": "text",
        "content": text_content,
        "text_length": len(text_content),
        "language": detect_language(text_content),
        "text_semantic_vector": text_semantic_vector.tolist(),
        "multimodal_vector": multimodal_vector.tolist(),
        "source_id": f"text_{hash(text_content)}",
        "created_time": get_current_time(),
        "metadata": metadata or {}
    }
    
    return client.insert("multimodal_rag", [data])
```

### å›¾åƒæ•°æ®æ’å…¥
```python
def insert_image_data(image_path, description=None):
    image = Image.open(image_path)
    
    # å¤šæ¨¡æ€ç‰¹å¾æå–
    image_visual_vector = get_clip_image_features([image])[0]
    multimodal_vector = image_visual_vector  # CLIPå›¾åƒå‘é‡å¯ç›´æ¥ç”¨ä½œå¤šæ¨¡æ€å‘é‡
    
    # å¦‚æœæœ‰å…³è”æ–‡æœ¬ï¼Œä¹Ÿæå–æ–‡æœ¬å‘é‡
    if description:
        text_vector = get_clip_text_features([description])[0]
    else:
        text_vector = [0] * 512
    
    data = {
        "data_type": "image",
        "file_path": image_path,
        "file_format": image_path.split('.')[-1],
        "image_dimensions": f"{image.width}x{image.height}",
        "image_visual_vector": image_visual_vector.tolist(),
        "multimodal_vector": multimodal_vector.tolist(),
        "text_semantic_vector": text_vector.tolist(),  # å¯é€‰ï¼šå›¾åƒæè¿°å‘é‡
        "source_id": f"image_{hash(image_path)}",
        "created_time": get_current_time(),
        "metadata": {
            "description": description,
            "file_size": os.path.getsize(image_path)
        }
    }
    
    return client.insert("multimodal_rag", [data])
```

### è¡¨æ ¼æ•°æ®æ’å…¥
```python
def insert_table_data(table_path, table_name, summary=None):
    # è¯»å–è¡¨æ ¼æ•°æ®
    if table_path.endswith('.csv'):
        df = pd.read_csv(table_path)
    else:
        df = pd.read_excel(table_path)
    
    # è¡¨æ ¼è¯­ä¹‰å‘é‡ï¼ˆåŸºäºè¡¨æ ¼å†…å®¹æ‘˜è¦ï¼‰
    table_content = generate_table_summary(df, summary)
    table_semantic_vector = get_text_bge_features([table_content])[0]
    multimodal_vector = get_clip_text_features([table_content])[0]
    
    # è¡¨æ ¼ç»“æ„å‘é‡ï¼ˆåŸºäºè¡¨ç»“æ„å’Œç»Ÿè®¡ä¿¡æ¯ï¼‰
    table_structural_vector = encode_table_structure(df)
    
    data = {
        "data_type": "table",
        "content": table_content,  # è¡¨æ ¼æ–‡æœ¬æ‘˜è¦
        "file_path": table_path,
        "table_name": table_name,
        "row_count": len(df),
        "column_count": len(df.columns),
        "table_structural_vector": table_structural_vector.tolist(),
        "text_semantic_vector": table_semantic_vector.tolist(),
        "multimodal_vector": multimodal_vector.tolist(),
        "source_id": f"table_{hash(table_path)}",
        "created_time": get_current_time(),
        "metadata": {
            "columns": list(df.columns),
            "dtypes": df.dtypes.astype(str).to_dict(),
            "summary_stats": generate_summary_stats(df)
        }
    }
    
    return client.insert("multimodal_rag", [data])
```

## ğŸ” å¤šæ¨¡æ€æ£€ç´¢ç­–ç•¥

### ç»Ÿä¸€æ£€ç´¢æ¥å£
```python
def multimodal_search(query, data_type=None, top_k=10):
    """
    æ”¯æŒå¤šç§æŸ¥è¯¢ç±»å‹çš„ç»Ÿä¸€æ£€ç´¢
    """
    if isinstance(query, str):
        # æ–‡æœ¬æŸ¥è¯¢
        query_vector = get_clip_text_features([query])[0]
        anns_field = "multimodal_vector"
        
    elif isinstance(query, Image.Image):
        # å›¾åƒæŸ¥è¯¢
        query_vector = get_clip_image_features([query])[0]
        anns_field = "multimodal_vector"
        
    elif isinstance(query, pd.DataFrame):
        # è¡¨æ ¼æŸ¥è¯¢
        table_content = generate_table_summary(query)
        query_vector = get_text_bge_features([table_content])[0]
        anns_field = "text_semantic_vector"
    
    # æ„å»ºè¿‡æ»¤æ¡ä»¶
    filter_expr = None
    if data_type:
        filter_expr = f"data_type == '{data_type}'"
    
    # æ‰§è¡Œæ£€ç´¢
    results = client.search(
        collection_name="multimodal_rag",
        data=[query_vector.tolist()],
        anns_field=anns_field,
        filter=filter_expr,
        limit=top_k,
        output_fields=["id", "data_type", "content", "file_path", "metadata"]
    )
    
    return process_search_results(results)
```

### è·¨æ¨¡æ€æ£€ç´¢ç¤ºä¾‹
```python
# æ–‡æœ¬æœå›¾
text_to_image_results = multimodal_search(
    query="é»‘è‰²çš„ç¬”è®°æœ¬ç”µè„‘", 
    data_type="image",
    top_k=5
)

# å›¾æœæ–‡
image_to_text_results = multimodal_search(
    query=user_uploaded_image,
    data_type="text", 
    top_k=5
)

# è¡¨æ ¼ç›¸ä¼¼æœç´¢
table_similarity_results = multimodal_search(
    query=reference_dataframe,
    data_type="table",
    top_k=3
)
```

## âš¡ æ€§èƒ½ä¼˜åŒ–è®¾è®¡

### 1. ç´¢å¼•ç­–ç•¥
```python
# ä¸ºä¸åŒå‘é‡å­—æ®µåˆ›å»ºä¸“ç”¨ç´¢å¼•
index_configs = {
    "multimodal_vector": {
        "index_type": "IVF_FLAT",
        "metric_type": "COSINE",
        "params": {"nlist": 1024}
    },
    "text_semantic_vector": {
        "index_type": "HNSW", 
        "metric_type": "COSINE",
        "params": {"M": 16, "efConstruction": 200}
    },
    "image_visual_vector": {
        "index_type": "IVF_SQ8",
        "metric_type": "COSINE", 
        "params": {"nlist": 512}
    }
}
```

### 2. åˆ†åŒºç­–ç•¥ï¼ˆå¤§è§„æ¨¡æ•°æ®ï¼‰
```python
# æŒ‰æ•°æ®ç±»å‹åˆ†åŒº
partition_names = ["text_partition", "image_partition", "table_partition"]

for partition in partition_names:
    client.create_partition(
        collection_name="multimodal_rag",
        partition_name=partition
    )
```

## ğŸ“ˆ æ‰©å±•æ€§è€ƒè™‘

### åŠ¨æ€å­—æ®µæ”¯æŒ
```python
# åˆ©ç”¨Milvusçš„åŠ¨æ€å­—æ®µå­˜å‚¨æ‰©å±•ä¿¡æ¯
dynamic_metadata = {
    "text_quality_score": 0.95,
    "image_quality_score": 0.88,
    "table_data_quality": 0.92,
    "extracted_keywords": ["ç¬”è®°æœ¬ç”µè„‘", "æ¸¸æˆæœ¬", "RTXæ˜¾å¡"],
    "content_categories": ["ç”µå­äº§å“", "ç”µè„‘"],
    "access_frequency": 156,
    "last_accessed": "2024-01-15 10:30:00"
}
```
