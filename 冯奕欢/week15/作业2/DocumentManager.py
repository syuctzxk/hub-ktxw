from pathlib import Path
from bs4 import BeautifulSoup
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_core.documents import Document
import re


class MarkdownDocumentManager:

    def __init__(self, directory_path, glob_pattern="./*.md"):
        self.directory_path = Path(directory_path)
        self.glob_pattern = glob_pattern
        self.processed_documents = []  # é¢„å¤„ç†åæ–‡æ¡£ï¼ˆHTMLè½¬MDè¡¨æ ¼ï¼‰
        self.all_chunks = []  # æœ€ç»ˆæ‹†åˆ†çš„Chunk

    # --------------------------
    # é€šç”¨å·¥å…·å‡½æ•°ï¼šHTMLè¡¨æ ¼è½¬æ ‡å‡†MDè¡¨æ ¼
    # --------------------------
    def html_table_to_md(self, html_content: str) -> str:
        """é€šç”¨HTMLè¡¨æ ¼è½¬MDè¡¨æ ¼ï¼šé€‚é…ä»»æ„HTMLè¡¨æ ¼ç»“æ„"""
        soup = BeautifulSoup(html_content, "html.parser")
        tables = soup.find_all("table")
        if not tables:
            return html_content

        for table in tables:
            md_table = "\n"
            rows = table.find_all("tr")
            if not rows:
                continue

            # é€šç”¨æå–å•å…ƒæ ¼ï¼ˆå…¼å®¹<th>/<td>ï¼Œæ— ä¸šåŠ¡é€»è¾‘ï¼‰
            all_cells = []
            for row in rows:
                cells = [
                    td.get_text(strip=True).replace("\n", " ").replace("  ", " ")
                    for td in row.find_all(["th", "td"])
                ]
                if cells:
                    all_cells.append(cells)

            # ç”Ÿæˆé€šç”¨MDè¡¨æ ¼ï¼ˆæ— ä¸šåŠ¡æ‹†åˆ†ï¼‰
            if all_cells:
                # è¡¨å¤´è¡Œ
                md_table += "| " + " | ".join(all_cells[0]) + " |\n"
                # åˆ†éš”çº¿
                md_table += "| " + " | ".join(["---"] * len(all_cells[0])) + " |\n"
                # æ•°æ®è¡Œ
                for row_cells in all_cells[1:]:
                    # è¡¥å…¨åˆ—æ•°ï¼ˆå…¼å®¹ä¸è§„åˆ™è¡¨æ ¼ï¼‰
                    row_cells += [""] * (len(all_cells[0]) - len(row_cells))
                    md_table += "| " + " | ".join(row_cells) + " |\n"

            # æ›¿æ¢åŸHTMLè¡¨æ ¼ä¸ºé€šç”¨MDè¡¨æ ¼
            html_content = html_content.replace(str(table), md_table)
        return html_content

    # --------------------------
    # é€šç”¨å·¥å…·å‡½æ•°ï¼šæå–MDæ–‡æ¡£ä¸­çš„æ‰€æœ‰å®Œæ•´è¡¨æ ¼
    # --------------------------
    def extract_all_tables(self, md_text: str) -> (str, list):
        """
        é€šç”¨æå–æ‰€æœ‰å®Œæ•´MDè¡¨æ ¼ï¼š
        è¿”å›ï¼šå»é™¤è¡¨æ ¼çš„çº¯æ–‡æœ¬ã€å®Œæ•´è¡¨æ ¼Chunkåˆ—è¡¨
        """
        # é€šç”¨MDè¡¨æ ¼æ­£åˆ™ï¼ˆåŒ¹é…|å¼€å¤´çš„è¡¨æ ¼è¡Œ+åˆ†éš”çº¿ï¼‰
        table_pattern = r"(?:\|.*\|\n){2,}"
        # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼ï¼ˆéè´ªå©ªåŒ¹é…ï¼Œé¿å…è·¨è¡¨æ ¼åˆå¹¶ï¼‰
        tables = re.findall(table_pattern, md_text, re.DOTALL)
        table_chunks = []

        if tables:
            # ä¸ºæ¯ä¸ªå®Œæ•´è¡¨æ ¼ç”Ÿæˆç‹¬ç«‹Chunkï¼ˆé€šç”¨è§„åˆ™ï¼‰
            for idx, table in enumerate(tables, 1):
                clean_table = table.strip()
                table_chunks.append(Document(
                    page_content=f"### è¡¨æ ¼ {idx}\n{clean_table}",
                    metadata={"type": "table", "table_index": idx}
                ))
            # ç§»é™¤åŸæ–‡æœ¬ä¸­çš„è¡¨æ ¼ï¼ˆä¿ç•™çº¯æ–‡æœ¬ï¼‰
            md_text_without_table = re.sub(table_pattern, "", md_text, re.DOTALL).strip()
        else:
            md_text_without_table = md_text

        return md_text_without_table, table_chunks

    # --------------------------
    # æ ¸å¿ƒæ­¥éª¤1ï¼šé€šç”¨åŠ è½½+é¢„å¤„ç†ï¼ˆé€‚é…ä»»æ„MDæ–‡æ¡£ï¼‰
    # --------------------------
    def load_and_preprocess(self):
        md_files = list(self.directory_path.glob(self.glob_pattern))
        for file in md_files:
            try:
                # é€šç”¨è¯»å–ï¼ˆå…¼å®¹UTF-8/GBKç¼–ç ï¼‰
                try:
                    raw_content = file.read_text(encoding="utf-8")
                except:
                    raw_content = file.read_text(encoding="gbk")

                # é€šç”¨é¢„å¤„ç†ï¼šHTMLè½¬MDè¡¨æ ¼ + æ¸…ç†ç‰¹æ®Šå­—ç¬¦
                processed_content = self.html_table_to_md(raw_content)
                processed_content = processed_content.replace("\r", "\n") \
                    .replace("\u3000", " ") \
                    .replace("  ", " ") \
                    .strip()

                self.processed_documents.append(Document(
                    page_content=processed_content,
                    metadata={"source": str(file), "file_name": file.name}
                ))
                print(f"âœ… é€šç”¨é¢„å¤„ç†å®Œæˆï¼š{file.name}")
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {file.name}ï¼š{str(e)}")
        print(f"\nğŸ“Š æ€»è®¡é¢„å¤„ç†æ–‡æ¡£æ•°ï¼š{len(self.processed_documents)}")

    # --------------------------
    # æ ¸å¿ƒæ­¥éª¤2ï¼šé€šç”¨æ‹†åˆ†ï¼ˆæ ‡é¢˜æ–‡æœ¬+å®Œæ•´è¡¨æ ¼ï¼‰
    # --------------------------
    def split_all_documents(self):
        # é€šç”¨æ ‡é¢˜æ‹†åˆ†è§„åˆ™ï¼ˆé€‚é…ä»»æ„MDæ ‡é¢˜å±‚çº§ï¼‰
        headers_to_split_on = [
            ("#", "Header 1"),
            ("##", "Header 2"),
            ("###", "Header 3"),
            ("####", "Header 4")
        ]
        text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)

        for doc in self.processed_documents:
            # 1. é€šç”¨æå–å®Œæ•´è¡¨æ ¼ä¸ºç‹¬ç«‹Chunk
            text_without_table, table_chunks = self.extract_all_tables(doc.page_content)

            # 2. é€šç”¨æ‹†åˆ†æ ‡é¢˜æ–‡æœ¬ï¼ˆæ— ä¸šåŠ¡é€»è¾‘ï¼‰
            text_sections = text_splitter.split_text(text_without_table)
            # ä¸ºæ–‡æœ¬Chunkè¡¥å……é€šç”¨å…ƒæ•°æ®
            for section in text_sections:
                section.metadata.update({
                    "source": doc.metadata["source"],
                    "file_name": doc.metadata["file_name"],
                    "type": "text"
                })

            # 3. ä¸ºè¡¨æ ¼Chunkè¡¥å……é€šç”¨å…ƒæ•°æ®
            for table_chunk in table_chunks:
                table_chunk.metadata.update({
                    "source": doc.metadata["source"],
                    "file_name": doc.metadata["file_name"]
                })

            # 4. åˆå¹¶æ‰€æœ‰Chunkï¼ˆæ–‡æœ¬+è¡¨æ ¼ï¼‰
            self.all_chunks.extend(text_sections)
            self.all_chunks.extend(table_chunks)

        # é€šç”¨ç»Ÿè®¡
        text_chunk_count = len([c for c in self.all_chunks if c.metadata["type"] == "text"])
        table_chunk_count = len([c for c in self.all_chunks if c.metadata["type"] == "table"])
        print(f"ğŸ“Š æ€»è®¡ç”Ÿæˆé€šç”¨Chunkæ•°ï¼š{len(self.all_chunks)}")
        print(f"   - æ–‡æœ¬Chunkæ•°ï¼š{text_chunk_count}")
        print(f"   - å®Œæ•´è¡¨æ ¼Chunkæ•°ï¼š{table_chunk_count}")