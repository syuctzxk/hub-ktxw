# 文档公式解析与智能问答三方案对比分析

## 一、项目背景与目标

本项目旨在解决**文档公式解析与智能问答**的问题，核心挑战包括：
1. 从PDF文档中准确提取包含数学公式的内容
2. 根据用户问题检索相关知识
3. 利用大语言模型理解公式并进行数值计算
4. 输出符合评测要求的答案格式

评测指标：**MSE（均方误差）**，分数越低越好。

---

## 二、三个方案的整体架构对比

| 维度 | Solu1 | Solu2 | Solu3 |
|-----|-------|-------|-------|
| **核心技术路线** | RAG + Thinking模型 + API推理 | 文本匹配 + 本地轻量LLM | RAG + 本地Ollama + SymPy计算 |
| **PDF解析方式** | dots.ocr (VLM模型) | PyPDFLoader | PyMuPDF (fitz) |
| **检索方式** | 向量检索 (Top-8) | 预先文本匹配 | 向量检索 (Top-3) |
| **嵌入模型** | Qwen3-Embedding-0.6B | - | shibing624/text2vec-base-chinese |
| **问答模型** | Qwen3-235B-A22B-Thinking (API) | Qwen2.5-7B (本地) | Qwen3-8B (Ollama本地) |
| **公式计算** | LLM直接生成答案 | LLM直接生成答案 | SymPy精确计算 + LLM回退 |
| **部署方式** | 云端API | 本地GPU推理 | 本地Ollama服务 |

---

## 三、详细技术方案对比

### 3.1 PDF文档解析

#### **Solu1：dots.ocr (VLM视觉语言模型)**
- **方法**：使用红书dots.ocr模型，通过vllm方式推理
- **流程**：PDF → 分页MD → 数据合并（data_prepare.py）
- **优点**：
  - 对复杂公式、图表的识别能力强
  - 支持LaTeX公式输出
  - 适合处理扫描件和图像文档
- **缺点**：
  - 推理速度较慢，需要vllm加速
  - 需要额外的模型部署
  - 资源消耗大

#### **Solu2：PyPDFLoader (文本提取)**
- **方法**：使用langchain的PyPDFLoader直接提取文本
- **优点**：
  - 实现简单，速度快
  - 对电子版PDF效果好
- **缺点**：
  - 对复杂公式、表格的提取效果一般
  - 无法处理图像化内容
  - 公式可能丢失格式

#### **Solu3：PyMuPDF/fitz (纯文本提取)**
- **方法**：使用fitz库逐页提取文本
- **优点**：
  - 速度最快，资源消耗最小
  - 适合纯文本内容
  - 易于集成
- **缺点**：
  - 对数学公式的保留有限
  - 无法识别图像内容
  - 格式保留能力弱

**小结**：Solu1在文档解析质量上最优，Solu3在效率上最优，Solu2居中。

---

### 3.2 知识检索策略

#### **Solu1：向量检索 (Top-8)**
```python
# 使用Qwen3-Embedding-0.6B编码
corpus_embeddings = embedder.encode_document(corpus, convert_to_tensor=True)
query_embedding = embedder.encode_query(query, convert_to_tensor=True)
# 检索Top-8最相关文档
scores, indices = torch.topk(similarity_scores, k=8)
```
- **特点**：高召回率策略，给模型更多上下文
- **优点**：降低漏检风险
- **缺点**：引入噪声，增加token消耗

#### **Solu2：预先文本匹配**
```python
# 生成matched.csv：每个问题预先匹配对应的知识
# 直接读取匹配结果，无需实时检索
```
- **特点**：离线预处理，问答时直接使用
- **优点**：推理速度快，无检索延迟
- **缺点**：
  - 需要人工或规则匹配
  - 缺乏灵活性
  - 匹配质量依赖规则设计

#### **Solu3：向量检索 (Top-3) + LLM二次选择**
```python
# 检索Top-3候选文档
top_k_scores, top_k_indices = torch.topk(cos_scores, k=3)
# Prompt中要求LLM首先选择最佳文档
"**第一步：选择最佳文档** 仔细阅读用户问题和下面提供的所有"备选文档"。
首先判断并选择出与用户问题**最相关**的那个文档。"
```
- **特点**：检索+LLM判断的两阶段策略
- **优点**：
  - 减少上下文长度
  - 让LLM参与文档选择，提高精准度
- **缺点**：可能错过相关文档

**小结**：Solu1追求高召回，Solu2追求效率，Solu3在准确率和效率间取得平衡。

---

### 3.3 大语言模型使用

#### **Solu1：Qwen3-235B-A22B-Thinking (API方式)**
```python
llm = ChatOpenAI(
    model="Qwen/Qwen3-235B-A22B-Thinking-2507",
    openai_api_base='https://api-inference.modelscope.cn/v1/',
)
```
- **模型规模**：235B参数（超大规模）
- **特点**：Thinking模型，具备强大的推理能力
- **优点**：
  - 理解能力强，能处理复杂逻辑
  - 自动选择合适公式
  - 无需本地GPU资源
- **缺点**：
  - API调用成本高
  - 网络延迟
  - 依赖外部服务稳定性

#### **Solu2：Qwen2.5-7B (本地部署)**
```python
model = AutoModelForCausalLM.from_pretrained(
    "./qwen2.5-7b",
    torch_dtype="auto",
    device_map="auto"
)
```
- **模型规模**：7B参数（轻量级）
- **Prompt特点**：要求直接输出数字或"估计是(值)"
- **优点**：
  - 本地部署，无API成本
  - 推理可控
  - 适合资源受限环境
- **缺点**：
  - 理解能力较弱
  - 可能无法处理复杂问题
  - 输出格式控制困难

#### **Solu3：Qwen3-8B (Ollama方式)**
```python
response = ollama.chat(
    model='qwen3:8b',
    messages=[{'role': 'user', 'content': prompt}]
)
```
- **模型规模**：8B参数（中等规模）
- **部署方式**：通过Ollama工具，易于管理
- **优点**：
  - 本地部署，推理稳定
  - Ollama简化模型管理
  - 8B规模在理解和效率间平衡
- **缺点**：
  - 需要本地GPU资源
  - 推理速度相对较慢

**小结**：Solu1性能最强但成本高，Solu2最轻量但能力受限，Solu3在性能和成本间取得平衡。

---

### 3.4 Prompt工程策略

#### **Solu1：引导式计算**
```python
template = '''
你是一位理工科的博士，下面给出问题query和多个参考公式列表，需要你给出最终的计算结果。
具体做法：
1. 参考公式存在多个，需要根据query来选择合适的公式
2. 如果问题可以不依赖参考公式，只要根据query就可以，可以直接计算。
3. 如果问题不明确或者无法给出具体结果，则返回无答案
4. 需要给出具体的计算公式、计算过程和最终的计算结果
5. 计算结果以json格式输出，例子"answer":'100'
'''
```
- **特点**：开放式，依赖模型自主推理
- **优点**：灵活，能处理多样化问题
- **缺点**：输出格式不稳定，需要复杂的后处理

#### **Solu2：简洁指令**
```python
prompt = f"请仔细阅读以下数学知识，并用一个数字回答我的数学问题，
只需要回答一个数字，可以是小数或多位数，
如果无法计算但可以估计结果，就回复我："估计是（估计结果）"，
不需要任何多余的解释或计算过程，我的问题是：{question}，
我的背景知识是{knowledge}"
```
- **特点**：极简风格，强调输出格式
- **优点**：减少token消耗，明确输出要求
- **缺点**：限制了模型的推理深度

#### **Solu3：结构化思维链**
```python
prompt_template = """
**第一步：选择最佳文档**
**第二步：分析问题意图** (numerical_calculation/formula_retrieval/conclusion_derivation)
**第三步：根据意图，严格按照JSON格式填充**
{
  "thought_process": "...",
  "question_intent": "...",
  "structured_data": {"formula": "...", "parameters": {...}},
  "llm_answer": "..."
}
**第四步：关于数值计算的特殊指令**
```
- **特点**：分步引导，结构化输出
- **优点**：
  - 思维链清晰
  - 意图分类便于后处理
  - JSON格式易于解析
- **缺点**：Prompt较长，增加token消耗

**小结**：Solu3的Prompt设计最为精巧，Solu1最灵活，Solu2最简洁。

---

### 3.5 答案生成与后处理

#### **Solu1：正则提取 + 手动修正**
```python
# 正则提取JSON答案
final_answer = re.search(r'\{\s*"answer"\s*:\s*"([^"]*)"\s*\}', data["answer"])
# 无答案时返回10
if "无答案" in answer_str:
    final_answer = 10
# 手动修改badcase（如单位换算问题）
# 纯代码得分2482.52，手动优化后476分
```
- **特点**：自动处理 + 人工优化
- **优点**：最终得分优秀
- **缺点**：
  - 依赖人工分析badcase
  - 不可自动化
  - 泛化能力弱

#### **Solu2：直接解析输出**
```python
# 直接读取模型输出的数字
content = tokenizer.decode(output_ids, skip_special_tokens=True)
# 保存为CSV
```
- **特点**：最小化后处理
- **优点**：流程简单
- **缺点**：
  - 依赖模型输出质量
  - 缺少鲁棒性处理

#### **Solu3：SymPy精确计算 + 智能映射**
```python
# 首先尝试SymPy精确计算
sympy_result = calculate_with_sympy(formula, final_params)
if sympy_result is not None:
    final_answer = sympy_result

# 意图映射策略
if intent == "formula_retrieval":
    return 1.0  # 成功识别公式
elif intent == "conclusion_derivation":
    # 根据关键词判断
    if "是/会/增长" in answer: return 1.0
    elif "否/不会/减少" in answer: return -1.0
    else: return 0.0
```
- **特点**：符号计算 + 规则映射
- **优点**：
  - 数值计算精确度高
  - 支持多种问题类型
  - 自动化程度高
- **缺点**：规则设计需要经验

**小结**：Solu1得分最优但依赖人工，Solu3自动化最好，Solu2最简单。

---

## 四、依赖与部署对比

### 4.1 核心依赖

| 库/工具 | Solu1 | Solu2 | Solu3 |
|--------|-------|-------|-------|
| **PDF解析** | dots.ocr + vllm | PyPDFLoader | PyMuPDF (fitz) |
| **向量模型** | Qwen3-Embedding-0.6B | - | shibing624/text2vec-base-chinese |
| **LLM** | API调用 | transformers本地加载 | Ollama |
| **计算库** | - | - | SymPy |
| **框架** | langchain | langchain | sentence-transformers |

### 4.2 资源需求

| 资源 | Solu1 | Solu2 | Solu3 |
|-----|-------|-------|-------|
| **GPU显存** | PDF解析阶段高 | ~20GB (7B模型) | ~10GB (8B模型+Ollama优化) |
| **网络依赖** | 强（API调用） | 无 | 无 |
| **存储空间** | dots.ocr模型大 | Qwen2.5-7B模型 | Qwen3-8B模型 + 向量模型 |
| **API成本** | 高 | 无 | 无 |

### 4.3 部署复杂度

**Solu1**：中等
- ✅ API调用简单
- ❌ dots.ocr模型部署复杂
- ❌ vllm环境配置困难

**Solu2**：低
- ✅ 纯本地部署
- ✅ 依赖少
- ❌ 需要手动生成matched.csv

**Solu3**：低
- ✅ Ollama简化部署
- ✅ 完整的自动化流程
- ✅ test.sh一键执行

---

## 五、优缺点总结

### 5.1 Solu1 (RAG + Thinking模型)

#### **优点**
1. ✅ **准确率最高**：235B Thinking模型理解能力强
2. ✅ **公式解析质量好**：dots.ocr对复杂公式支持优秀
3. ✅ **最终得分优秀**：手动优化后达到476分
4. ✅ **高召回策略**：Top-8检索降低漏检风险

#### **缺点**
1. ❌ **成本高**：API调用费用昂贵，token消耗大
2. ❌ **部署复杂**：dots.ocr + vllm环境配置困难
3. ❌ **依赖外部服务**：网络稳定性影响推理
4. ❌ **不可完全自动化**：依赖人工分析和修正badcase
5. ❌ **泛化能力存疑**：手动优化针对特定数据集

#### **适用场景**
- 对准确率要求极高的场景
- 有充足API预算
- 允许人工介入优化

---

### 5.2 Solu2 (文本匹配 + 轻量LLM)

#### **优点**
1. ✅ **部署最简单**：纯本地，依赖少
2. ✅ **推理速度快**：预匹配 + 7B模型轻量
3. ✅ **资源消耗低**：适合GPU资源受限环境
4. ✅ **无API成本**：完全本地化
5. ✅ **流程清晰**：read_pdf → match → qa

#### **缺点**
1. ❌ **模型能力弱**：7B模型理解复杂逻辑困难
2. ❌ **检索策略简单**：预匹配缺乏灵活性
3. ❌ **缺少后处理**：输出格式控制弱
4. ❌ **公式解析一般**：PyPDFLoader对复杂内容提取有限
5. ❌ **需要手动匹配**：matched.csv生成过程不明确

#### **适用场景**
- 资源受限环境
- 问题类型相对简单
- 对准确率要求不高但需要快速响应

---

### 5.3 Solu3 (RAG + Ollama + SymPy)

#### **优点**
1. ✅ **架构最优雅**：两阶段设计清晰（推理→后处理）
2. ✅ **完全自动化**：test.sh一键执行，无人工干预
3. ✅ **计算精确**：SymPy保证数值计算准确性
4. ✅ **Prompt设计精巧**：结构化输出 + 意图分类
5. ✅ **易于部署**：Ollama大幅简化LLM管理
6. ✅ **本地化部署**：无外部依赖，推理稳定
7. ✅ **文档完善**：README详细，易于复现

#### **缺点**
1. ❌ **公式解析基础**：fitz对复杂公式提取有限
2. ❌ **Top-3可能漏检**：检索数量少可能错过相关文档
3. ❌ **后处理规则依赖**：意图映射需要精心设计
4. ❌ **8B模型能力中等**：不如235B模型强大
5. ❌ **SymPy局限性**：复杂公式可能解析失败

#### **适用场景**
- 需要完全本地化部署
- 追求工程化和自动化
- 有一定GPU资源（8B模型可接受）
- 看重代码质量和可维护性

---

## 六、核心技术创新点对比

| 创新点 | Solu1 | Solu2 | Solu3 |
|--------|-------|-------|-------|
| **PDF解析** | VLM模型（创新⭐⭐⭐） | 传统方法 | 传统方法 |
| **检索策略** | 高召回Top-8 | 预匹配（创新⭐⭐） | 精简Top-3 + LLM二次选择（创新⭐⭐） |
| **计算方法** | LLM直接生成 | LLM直接生成 | SymPy符号计算（创新⭐⭐⭐） |
| **Prompt设计** | 引导式 | 极简式 | 结构化思维链（创新⭐⭐⭐） |
| **后处理** | 人工优化（创新⭐） | 无 | 智能映射（创新⭐⭐） |

---

## 七、性能与成本对比（估算）

| 指标 | Solu1 | Solu2 | Solu3 |
|-----|-------|-------|-------|
| **准确率** | ⭐⭐⭐⭐⭐ (476分) | ⭐⭐⭐ | ⭐⭐⭐⭐ |
| **推理速度** | ⭐⭐ (API延迟) | ⭐⭐⭐⭐⭐ (最快) | ⭐⭐⭐ |
| **部署难度** | ⭐⭐ (复杂) | ⭐⭐⭐⭐⭐ (简单) | ⭐⭐⭐⭐ (易) |
| **自动化程度** | ⭐⭐ (需人工) | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ (完全) |
| **成本** | ⭐ (高API费用) | ⭐⭐⭐⭐ (低) | ⭐⭐⭐⭐⭐ (最低) |
| **可维护性** | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐⭐ (代码最清晰) |
| **泛化能力** | ⭐⭐ (依赖手动优化) | ⭐⭐⭐ | ⭐⭐⭐⭐ |

---
